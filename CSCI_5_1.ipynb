{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering: Basic Approach**"
      ],
      "metadata": {
        "id": "OyL_2btMH5GW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.  One-Hot Encoding**\n"
      ],
      "metadata": {
        "id": "il059GJ7IAcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "a9qRzx0lHLc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTvKjw6nF-fU",
        "outputId": "224517ad-0626-4235-8ca9-c08c52eed53a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Sentences : ['the cat is on the mat', 'my dog and cat are the best', 'the locals are playing']\n",
            "vocabulary : {'the': 1, 'cat': 2, 'is': 3, 'on': 4, 'mat': 5, 'my': 6, 'dog': 7, 'and': 8, 'are': 9, 'best': 10, 'locals': 11, 'playing': 12}\n",
            "OneHotEncoded vector for sentence : \" the cat is on the mat \"is \n",
            " [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "Text = \"\"\"The cat is on the mat.\n",
        "          My dog and cat are the best.\n",
        "          The locals are playing.\"\"\"\n",
        "\n",
        "sentences = sent_tokenize(Text)\n",
        "sentences = [sent.lower().replace(\".\", \"\") for sent in sentences]\n",
        "print('Tokenized Sentences :', sentences)\n",
        "\n",
        "# Create the vocabulary\n",
        "vocab = {}\n",
        "count = 0\n",
        "for sent in sentences:\n",
        "    for word in sent.split():\n",
        "        if word not in vocab:\n",
        "            count = count + 1\n",
        "            vocab[word] = count\n",
        "print('vocabulary :', vocab)\n",
        "\n",
        "# One Hot Encoding\n",
        "def OneHotEncoder(text):\n",
        "    onehot_encoded = []\n",
        "    for word in text.split():\n",
        "        temp = [0]*len(vocab)\n",
        "        if word in vocab:\n",
        "            temp[vocab[word]-1] = 1\n",
        "            onehot_encoded.append(temp)\n",
        "    return onehot_encoded\n",
        "\n",
        "\n",
        "# print('\\n',sentences[0])\n",
        "print('OneHotEncoded vector for sentence : \"',\n",
        "     sentences[0], '\"is \\n', OneHotEncoder(sentences[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.  Bag Of Words (BOW)**"
      ],
      "metadata": {
        "id": "rRn3DmTUIJH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the `CountVectorizer` class to build a bag of words representation of the sentences."
      ],
      "metadata": {
        "id": "3n7hDdiFJ7Ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "Text = \"\"\"The cat is on the mat.\n",
        "          My dog and cat are the best.\n",
        "          The locals are playing.\"\"\"\n",
        "\n",
        "# TOKENIZATION\n",
        "sentences = sent_tokenize(Text)\n",
        "sentences = [sent.lower().replace(\".\",\"\") for sent in sentences]\n",
        "print('Our Corpus:',sentences)\n",
        "\n",
        "#CountVectorizer : Convert a collection of text documents to a matrix of token counts.\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "# fit & transform will represent each sentences as BOW representation\n",
        "BOW = count_vect.fit_transform(sentences)\n",
        "\n",
        "# Get the vocabulary\n",
        "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
        "\n",
        "# Get the sorted vocabulary by value\n",
        "print(\"Our sorted vocabulary: \", sorted(count_vect.vocabulary_))\n",
        "\n",
        "#see the BOW representation\n",
        "print(f\"BoW representation for {sentences[0]} {BOW[0].toarray()}\")\n",
        "print(f\"BoW representation for {sentences[1]} {BOW[1].toarray()}\")\n",
        "print(f\"BoW representation for {sentences[2]} {BOW[2].toarray()}\")\n",
        "\n",
        "# BOW representation for a new text\n",
        "BOW_ = count_vect.transform([\"learning NLP is good\"])\n",
        "print(\"Bow representation for 'learning NLP is good':\", BOW_.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgYhSQ1CHtka",
        "outputId": "fbbb1107-130e-4b3a-d59f-b0c85f5e9bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our Corpus: ['the cat is on the mat', 'my dog and cat are the best', 'the locals are playing']\n",
            "Our vocabulary:  {'the': 11, 'cat': 3, 'is': 5, 'on': 9, 'mat': 7, 'my': 8, 'dog': 4, 'and': 0, 'are': 1, 'best': 2, 'locals': 6, 'playing': 10}\n",
            "Our sorted vocabulary:  ['and', 'are', 'best', 'cat', 'dog', 'is', 'locals', 'mat', 'my', 'on', 'playing', 'the']\n",
            "BoW representation for the cat is on the mat [[0 0 0 1 0 1 0 1 0 1 0 2]]\n",
            "BoW representation for my dog and cat are the best [[1 1 1 1 1 0 0 0 1 0 0 1]]\n",
            "BoW representation for the locals are playing [[0 1 0 0 0 0 1 0 0 0 1 1]]\n",
            "Bow representation for 'learning NLP is good': [[0 0 0 0 0 1 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.  Bag of n-grams**"
      ],
      "metadata": {
        "id": "5vIYOsetLjUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "Text = \"\"\"The cat is on the mat.\n",
        "          My dog and cat are the best.\n",
        "          The locals are playing.\"\"\"\n",
        "\n",
        "# TOKENIZATION\n",
        "sentences = sent_tokenize(Text)\n",
        "sentences = [sent.lower().replace(\".\", \"\") for sent in sentences]\n",
        "print('Our Corpus:', sentences)\n",
        "\n",
        "# Ngram vectorization example with count\n",
        "# vectorizer and uni, bi, trigrams\n",
        "count_vect = CountVectorizer(ngram_range=(1, 3))\n",
        "\n",
        "# fit & transform will represent each sentences\n",
        "# as Bag of n-grams representation\n",
        "BOW_nGram = count_vect.fit_transform(sentences)\n",
        "\n",
        "# Get the vocabulary\n",
        "print(\"Our vocabulary:\\n\", count_vect.vocabulary_)\n",
        "\n",
        "# Get the sorted vocabulary\n",
        "print(\"Our sorted vocabulary:\\n\", sorted(count_vect.vocabulary_) )\n",
        "\n",
        "\n",
        "# see the Bag of n-grams representation\n",
        "print('Ngram representation for \"{}\" is {}'\n",
        "\t.format(sentences[0], BOW_nGram[0].toarray()))\n",
        "print('Ngram representation for \"{}\" is {}'\n",
        "\t.format(sentences[1], BOW_nGram[1].toarray()))\n",
        "print('Ngram representation for \"{}\" is {}'.\n",
        "\tformat(sentences[2], BOW_nGram[2].toarray()))\n",
        "\n",
        "# Bag of n-grams representation for a new text\n",
        "BOW_nGram_ = count_vect.transform([\"dog and cat are playing together\"])\n",
        "print(\"Ngram representation for 'dog and cat are playing together' is\",\n",
        "\tBOW_nGram_.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG-Ee5vsLqdy",
        "outputId": "3676b25e-4ba8-4ca9-bc7a-ed1a35f508cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our Corpus: ['the cat is on the mat', 'my dog and cat are the best', 'the locals are playing']\n",
            "Our vocabulary:\n",
            " {'the': 30, 'cat': 8, 'is': 16, 'on': 26, 'mat': 22, 'the cat': 32, 'cat is': 11, 'is on': 17, 'on the': 27, 'the mat': 36, 'the cat is': 33, 'cat is on': 12, 'is on the': 18, 'on the mat': 28, 'my': 23, 'dog': 13, 'and': 0, 'are': 3, 'best': 7, 'my dog': 24, 'dog and': 14, 'and cat': 1, 'cat are': 9, 'are the': 5, 'the best': 31, 'my dog and': 25, 'dog and cat': 15, 'and cat are': 2, 'cat are the': 10, 'are the best': 6, 'locals': 19, 'playing': 29, 'the locals': 34, 'locals are': 20, 'are playing': 4, 'the locals are': 35, 'locals are playing': 21}\n",
            "Our sorted vocabulary:\n",
            " ['and', 'and cat', 'and cat are', 'are', 'are playing', 'are the', 'are the best', 'best', 'cat', 'cat are', 'cat are the', 'cat is', 'cat is on', 'dog', 'dog and', 'dog and cat', 'is', 'is on', 'is on the', 'locals', 'locals are', 'locals are playing', 'mat', 'my', 'my dog', 'my dog and', 'on', 'on the', 'on the mat', 'playing', 'the', 'the best', 'the cat', 'the cat is', 'the locals', 'the locals are', 'the mat']\n",
            "Ngram representation for \"the cat is on the mat\" is [[0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 0 2 0 1 1 0 0\n",
            "  1]]\n",
            "Ngram representation for \"my dog and cat are the best\" is [[1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0\n",
            "  0]]\n",
            "Ngram representation for \"the locals are playing\" is [[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1\n",
            "  0]]\n",
            "Ngram representation for 'dog and cat are playing together' is [[1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            "  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.  TF-IDF**"
      ],
      "metadata": {
        "id": "ZlPCBZ7GLdsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "Text = \"\"\"The cat is on the mat.\n",
        "          My dog and cat are the best.\n",
        "          The locals are playing.\"\"\"\n",
        "\n",
        "# TOKENIZATION\n",
        "sentences = sent_tokenize(Text)\n",
        "sentences = [sent.lower().replace(\".\", \"\") for sent in sentences]\n",
        "print('Our Corpus:', sentences)\n",
        "\n",
        "# TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(sentences)\n",
        "\n",
        "# All words in the vocabulary.\n",
        "print(\"vocabulary\", tfidf.get_feature_names_out())\n",
        "# IDF value for all words in the vocabulary\n",
        "print(\"IDF for all words in the vocabulary :\\n\", tfidf.idf_)\n",
        "\n",
        "# TFIDF representation for all documents in our corpus\n",
        "print('\\nTFIDF representation for \"{}\" is \\n{}'\n",
        "\t.format(sentences[0], tfidf_matrix[0].toarray()))\n",
        "print('TFIDF representation for \"{}\" is \\n{}'\n",
        "\t.format(sentences[1], tfidf_matrix[1].toarray()))\n",
        "print('TFIDF representation for \"{}\" is \\n{}'\n",
        "\t.format(sentences[2],tfidf_matrix[2].toarray()))\n",
        "\n",
        "# TFIDF representation for a new text\n",
        "matrix = tfidf.transform([\"dog and cat are playing together\"])\n",
        "print(\"\\nTFIDF representation for 'dog and cat are playing together' is\\n\",\n",
        "\tmatrix.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al9-hypVKSDN",
        "outputId": "9605f432-d227-4374-acd3-29e2cb26650e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our Corpus: ['the cat is on the mat', 'my dog and cat are the best', 'the locals are playing']\n",
            "vocabulary ['and' 'are' 'best' 'cat' 'dog' 'is' 'locals' 'mat' 'my' 'on' 'playing'\n",
            " 'the']\n",
            "IDF for all words in the vocabulary :\n",
            " [1.69314718 1.28768207 1.69314718 1.28768207 1.69314718 1.69314718\n",
            " 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718 1.        ]\n",
            "\n",
            "TFIDF representation for \"the cat is on the mat\" is \n",
            "[[0.         0.         0.         0.34101521 0.         0.44839402\n",
            "  0.         0.44839402 0.         0.44839402 0.         0.52965746]]\n",
            "TFIDF representation for \"my dog and cat are the best\" is \n",
            "[[0.4261835  0.32412354 0.4261835  0.32412354 0.4261835  0.\n",
            "  0.         0.         0.4261835  0.         0.         0.25171084]]\n",
            "TFIDF representation for \"the locals are playing\" is \n",
            "[[0.         0.44451431 0.         0.         0.         0.\n",
            "  0.5844829  0.         0.         0.         0.5844829  0.34520502]]\n",
            "\n",
            "TFIDF representation for 'dog and cat are playing together' is\n",
            " [[0.49047908 0.37302199 0.         0.37302199 0.49047908 0.\n",
            "  0.         0.         0.         0.         0.49047908 0.        ]]\n"
          ]
        }
      ]
    }
  ]
}